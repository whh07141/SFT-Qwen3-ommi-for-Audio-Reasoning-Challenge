# SFT-Qwen3-ommi-for-Audio-Reasoning-Challenge


æœ¬é¡¹ç›®æ˜¯Interspeech 2026 éŸ³é¢‘æ¨ç†æŒ‘æˆ˜ï¼ˆAudio Reasoning Challengeï¼‰çš„è§£å†³æ–¹æ³•ã€‚æˆ‘ä»¬åˆ©ç”¨

## å¿«é€Ÿå¼€å§‹

- **å…ˆå†³æ¡ä»¶**ï¼šPython 3.8+ï¼ˆæ¨è 3.10+ï¼‰ï¼ŒGitï¼Œè‹¥ä½¿ç”¨ GPU è¯·å®‰è£…å¯¹åº”çš„ CUDA é©±åŠ¨å’Œ cuDNNã€‚

- **å»ºè®®ç¯å¢ƒï¼ˆç¤ºä¾‹ï¼‰**ï¼š

  ```bash
  python -m venv .venv
  source .venv/bin/activate
  pip install --upgrade pip
  pip install -r requirements.txt
  ```

- **å®‰è£…è¯´æ˜**ï¼šè¯·æ ¹æ®ä½ ä½¿ç”¨çš„ç¡¬ä»¶ï¼ˆCPU/GPUï¼‰è°ƒæ•´ `requirements.txt` ä¸­çš„ `torch` ç‰ˆæœ¬ï¼Œä¾‹å¦‚ä½¿ç”¨ CUDA ç‰ˆæœ¬å¯¹åº”çš„ `torch` wheel æˆ–å®˜æ–¹å®‰è£…å‘½ä»¤ã€‚

- **è¿è¡Œç¤ºä¾‹**ï¼š

  ```bash
  # æŸ¥çœ‹è®­ç»ƒè„šæœ¬å¸®åŠ©
  python scripts/train.py --help

  # è¿è¡Œä¸€æ¬¡å¿«é€Ÿç¤ºä¾‹ï¼ˆæ›¿æ¢ä¸ºå®é™…è„šæœ¬ä¸å‚æ•°ï¼‰
  python scripts/train.py --config configs/finetune_cot.yaml --data_dir /path/to/data --output_dir ./checkpoints/debug
  ```

è¯·åœ¨ `requirements.txt` ä¸­æ ¹æ®ç›®æ ‡ç¡¬ä»¶å¡«å…¥åˆé€‚çš„ä¾èµ–ï¼ˆä»“åº“å†…å·²æ·»åŠ ç¤ºä¾‹ä¾èµ–ï¼‰ã€‚

## ç›®å½•ç»“æ„ï¼ˆç¤ºä¾‹ï¼‰

- `data/`ï¼šæ•°æ®é›†ä¸é¢„å¤„ç†è„šæœ¬
- `src/`ï¼šä¸»è¦ä»£ç ï¼ˆæ¨¡å‹ã€è®­ç»ƒã€è¯„ä¼°ï¼‰
- `configs/`ï¼šé…ç½®æ–‡ä»¶
- `scripts/`ï¼šè¾…åŠ©è„šæœ¬ï¼ˆè®­ç»ƒã€æ¨ç†ã€è¯„ä¼°ï¼‰

## è´¡çŒ®

æ¬¢è¿è´¡çŒ®ã€‚è¯·åœ¨æäº¤å‰åˆ›å»º issue è®¨è®ºä¸»è¦æ”¹åŠ¨ï¼Œå¹¶éµå¾ªé¡¹ç›®ä»£ç é£æ ¼ä¸æµ‹è¯•è§„èŒƒã€‚

## è®¸å¯è¯

è¯·æ ¹æ®å®é™…éœ€è¦æ·»åŠ è®¸å¯è¯ä¿¡æ¯ã€‚

## è”ç³»æ–¹å¼

å¦‚éœ€å¸®åŠ©æˆ–åä½œï¼Œè¯·æ‰“å¼€ issue æˆ–è”ç³»ä»“åº“ç»´æŠ¤è€…ã€‚
# Audio-Reasoner å¾®è°ƒ Qwen3-ommi-thinking-30Bï¼ˆåŸºäº Llamaractoryï¼‰ / Fine-tuning Qwen3-ommi-thinking-30B on Audio-Reasoner (Llamaractory)

**ç®€çŸ­è¯´æ˜ (Overview)** âœ…
- æœ¬ä»“åº“è®°å½•äº†ä½¿ç”¨ **Llamaractory** æ¡†æ¶ï¼ŒåŸºäº **Audio-Reasoner** æ•°æ®é›†å¯¹ **Qwen3-ommi-thinking-30B** è¿›è¡Œ COTï¼ˆChain-of-Thoughtï¼‰é£æ ¼å¾®è°ƒçš„å®Œæ•´æµç¨‹ã€‚è¯¥ README ä¸ºä¸­è‹±åŒè¯­ç‰ˆï¼ŒåŒ…å«è®­ç»ƒã€æ¨ç†ã€è¯„ä¼°ã€æ¨¡å‹å¡ä¸å¤ç°æ­¥éª¤ã€‚

- This repo documents the end-to-end process for fine-tuning **Qwen3-ommi-thinking-30B** with **Chain-of-Thought (CoT)** supervision on the **Audio-Reasoner** dataset using **Llamaractory**. This README is bilingual (ZH/EN).

---

## ç›®å½• / Table of Contents
1. é¡¹ç›®ç®€ä»‹ / Project Summary
2. æ•°æ®ä¸é¢„å¤„ç† / Data & Preprocessing
3. å¾®è°ƒé…ç½®ä¸è®­ç»ƒç¤ºä¾‹ / Fine-tuning Config & Example Commands
4. æ¨ç†ä¸æ¼”ç¤º / Inference & Demo
5. è¯„ä¼° / Evaluation
6. æ¨¡å‹å¡ä¸ä½¿ç”¨å£°æ˜ / Model Card & Usage Notes
7. å¤ç°è¯´æ˜ / Reproducibility
8. å¸¸è§é—®é¢˜ / FAQ
9. å¼•ç”¨ / Citations

---

## 1. é¡¹ç›®ç®€ä»‹ / Project Summary
**ä¸­æ–‡**ï¼šæœ¬é¡¹ç›®ç›®æ ‡æ˜¯è®© Qwen3-ommi-thinking-30B åœ¨ Audio-Reasoner ä»»åŠ¡ä¸Šé€šè¿‡ Chain-of-Thought é£æ ¼çš„æ•°æ®è¿›è¡Œå¾®è°ƒï¼Œä»è€Œæé«˜å¤æ‚éŸ³é¢‘æ¨ç†é—®é¢˜çš„é€æ­¥æ¨ç†èƒ½åŠ›ä¸æœ€ç»ˆç­”æ¡ˆå‡†ç¡®ç‡ã€‚

**English**: Goal is to improve step-by-step reasoning and final answer accuracy of Qwen3-ommi-thinking-30B on Audio-Reasoner by fine-tuning with Chain-of-Thought style supervision.

---

## 2. æ•°æ®ä¸é¢„å¤„ç† / Data & Preprocessing
**ä¸­æ–‡**ï¼š
- æ•°æ®é›†ï¼šAudio-Reasonerï¼ˆè¯·åœ¨ `DATA_DIR` ä¸­æ”¾ç½®å¹¶ä¿æŒåŸå§‹ç»“æ„ï¼‰ã€‚
- æ ¼å¼ï¼šæ¯æ¡æ ·ä¾‹åŒ…å«éŸ³é¢‘æ ‡è¯†ã€è½¬å½•/ç‰¹å¾ï¼ˆå¦‚æœ‰ï¼‰ã€é—®é¢˜ã€COT æ¨ç†è¿‡ç¨‹ï¼ˆè®­ç»ƒæ—¶çš„ç›®æ ‡ï¼‰ã€ä»¥åŠæœ€ç»ˆç­”æ¡ˆã€‚
- é¢„å¤„ç†è¦ç‚¹ï¼š
  - éŸ³é¢‘å¤„ç†ï¼šå¦‚æœæ¨¡å‹è¾“å…¥åŒ…å«éŸ³é¢‘ç‰¹å¾ï¼ˆå¦‚ log-mel, wav2vec ç‰¹å¾ï¼‰ï¼Œè¯·åœ¨é¢„å¤„ç†é˜¶æ®µç”Ÿæˆ `.npy` / `.pt` ç‰¹å¾å¹¶ä¿å­˜ç´¢å¼•è¡¨ã€‚
  - æ–‡æœ¬æ ¼å¼åŒ–ï¼šå°† Chain-of-Thought (é€æ­¥æ¨ç†) ä¸æœ€ç»ˆç­”æ¡ˆæ˜ç¡®åˆ†éš”ï¼ˆç¤ºä¾‹è§ä¸‹ï¼‰ã€‚
  - æ•°æ®åˆ‡åˆ†ï¼šè®­ç»ƒ/éªŒè¯/æµ‹è¯•ï¼ˆä¾‹å¦‚ 80/10/10ï¼‰ã€‚

**English**:
- Dataset: Audio-Reasoner (place raw data under `DATA_DIR`).
- Format: each item includes audio id, transcript/features (if any), question, CoT reasoning (target during SFT), and final answer.
- Preprocessing highlights:
  - Audio features: preprocess audio to fixed features if needed (e.g., log-mel, wav2vec). Save indexing table.
  - Text formatting: separate COT chain and final answer explicitly (see example below).
  - Split: Train/Val/Test (e.g., 80/10/10).

Example text training instance (JSON-like):
```
{
  "id": "xxx",
  "audio_feat": "path/to/feat.npy",
  "question": "ç»™å‡ºè¿™æ®µéŸ³é¢‘ä¸­è¯´è¯äººçš„æƒ…ç»ªåŠç†ç”±ã€‚",
  "cot": "é¦–å…ˆâ€¦ï¼ˆé€æ­¥æ¨ç†ï¼‰â€¦å› æ­¤ç»“è®ºæ˜¯â€¦", 
  "answer": "æ„¤æ€’"
}
```

---

## 3. å¾®è°ƒé…ç½®ä¸è®­ç»ƒç¤ºä¾‹ / Fine-tuning Config & Example Commands ğŸ”§
**ä¸­æ–‡è¯´æ˜è¦ç‚¹**ï¼š
- æ¨èä½¿ç”¨æ··åˆç²¾åº¦ï¼ˆfp16 æˆ– bf16ï¼‰ã€æ¢¯åº¦ç´¯ç§¯å’Œé€‚å½“çš„ batch-size/å­¦ä¹ ç‡ç­–ç•¥ã€‚30B æ¨¡å‹é€šå¸¸éœ€è¦å¤§æ˜¾å­˜ï¼ˆå»ºè®® A100 80GB æˆ–ä½¿ç”¨ ZeRO/åˆ†å¸ƒå¼ç­–ç•¥ / 8bit å­˜å‚¨ï¼‰ã€‚
- å¦‚æœä½¿ç”¨ LoRA æˆ–å‚æ•°é«˜æ•ˆå¾®è°ƒ (PEFT)ï¼Œå¯æ˜¾è‘—é™ä½æ˜¾å­˜éœ€æ±‚å¹¶ä¿æŒè®­ç»ƒé€Ÿåº¦ã€‚

**Suggested dependencies (ç¤ºä¾‹)**:
- Python >= 3.10
- torch >= 2.x
- transformers
- accelerate / deepspeed
- bitsandbytes (å¦‚ç”¨ 8-bit)
- llama/llamaractoryï¼ˆä½ ä½¿ç”¨çš„ Llamaractory ç‰ˆæœ¬ï¼‰

ç¤ºä¾‹è®­ç»ƒé…ç½® (YAML æ¨¡æ¿)ï¼š
```yaml
model:
  base_model: qwen3-ommi-thinking-30b
  dtype: bf16
training:
  batch_size: 1               # per device
  gradient_accumulation_steps: 8
  epochs: 3
  lr: 2e-5
  weight_decay: 0.01
  warmup_steps: 100
  max_grad_norm: 1.0
optimizer:
  name: adamw
  betas: [0.9, 0.95]
lora:                       # å¦‚æœä½¿ç”¨ LoRA
  r: 16
  alpha: 32
  dropout: 0.05
data:
  train_file: data/train.jsonl
  val_file: data/val.jsonl
  tokenizer: path/to/tokenizer
logging:
  logging_steps: 50
  save_steps: 2000

```

ç¤ºä¾‹è®­ç»ƒå‘½ä»¤ï¼ˆæ ¹æ®å®é™…è®­ç»ƒè„šæœ¬è°ƒæ•´ï¼‰:
```bash
# å•èŠ‚ç‚¹å¤šå¡ï¼ˆç¤ºä¾‹ï¼‰
python train.py --config configs/finetune_cot.yaml --data_dir /path/to/data --output_dir ./checkpoints/finetuned_cot

# ä½¿ç”¨ accelerate
accelerate launch --config_file accelerate_config.yaml train.py --config configs/finetune_cot.yaml
```

è®­ç»ƒè¦ç‚¹ï¼š
- ä½¿ç”¨ seed å›ºå®šåŒ–ä»¥ä¾¿å¤ç° (e.g., seed=42)
- å®šæœŸä¿å­˜éªŒè¯æ£€æŸ¥ç‚¹å¹¶ç›‘æ§éªŒè¯é›†ä¸Šçš„æœ€ç»ˆç­”æ¡ˆå‡†ç¡®åº¦å’Œ COT è´¨é‡

---

## 4. æ¨ç†ä¸æ¼”ç¤º / Inference & Demo â–¶ï¸
**æ ¼å¼ï¼ˆPrompt Templateï¼‰**
- ä¸ºäº†å¼•å¯¼æ¨¡å‹ç”Ÿæˆ Chain-of-Thoughtï¼ˆé€æ­¥æ¨ç†ï¼‰ï¼Œæç¤ºä¸­æ˜¾å¼è¦æ±‚æ¨ç†è¿‡ç¨‹ï¼šä¾‹å¦‚ `è¯·é€æ­¥æ¨ç†å¹¶ç»™å‡ºæœ€ç»ˆç­”æ¡ˆï¼ˆStep-by-step, then final answerï¼‰`ã€‚

ç¤ºä¾‹ Promptï¼ˆä¸­æ–‡/è‹±æ–‡åŒè¯­ç¤ºä¾‹ï¼‰:
```
System: ä½ æ˜¯ä¸€ä¸ªæ“…é•¿éŸ³é¢‘æ¨ç†çš„åŠ©æ‰‹ï¼Œè¯·åœ¨å›ç­”æ—¶å…ˆåˆ—å‡ºè¯¦ç»†æ¨ç†æ­¥éª¤ï¼ˆChain-of-Thoughtï¼‰ï¼Œç„¶åç»™å‡ºæœ€ç»ˆç­”æ¡ˆã€‚
User: é—®é¢˜ï¼š<é—®é¢˜æ–‡æœ¬>
éŸ³é¢‘æè¿°ï¼š<éŸ³é¢‘è½¬å½•æˆ–ç‰¹å¾ç®€è¿°>
è¯·å¼€å§‹é€æ­¥æ¨ç†å¹¶ç»™å‡ºæœ€ç»ˆç­”æ¡ˆã€‚
```

æ¨èæ¨ç†è¶…å‚æ•°ï¼š
- temperature: 0.0 - 0.7 (0.0 ç”¨äºç¡®å®šæ€§ç­”æ¡ˆ)
- top_p: 0.9
- max_new_tokens: 256-512
- stop_sequences: ["\n\n", "Answer:"]

ç¤ºä¾‹æ¨ç†å‘½ä»¤ï¼š
```bash
python infer.py --model ./checkpoints/finetuned_cot --prompt_file examples/prompt.jsonl --temperature 0.2 --out predictions.jsonl
```

Self-consistencyï¼ˆç¨³å¥æ€§è¯„ä¼°ï¼‰æ–¹æ³•ï¼šå¤šæ¬¡é‡‡æ ·ç”Ÿæˆå¤šæ¡ COT å¹¶å¯¹æœ€ç»ˆç­”æ¡ˆåšå¤šæ•°æŠ•ç¥¨ï¼Œä»¥æé«˜ç²¾åº¦ã€‚

---

## 5. è¯„ä¼° / Evaluation âœ…
**è‡ªåŠ¨åŒ–æŒ‡æ ‡å»ºè®®**ï¼š
- æœ€ç»ˆç­”æ¡ˆå‡†ç¡®ç‡ï¼ˆAccuracy on final answerï¼‰ â€” ä¸»æŒ‡æ ‡ã€‚
- Chain-of-Thought è´¨é‡ï¼šå¯é‡‡ç”¨ BLEU / ROUGE / BERTScore ä¸å‚è€ƒ COT æ¯”è¾ƒï¼Œä½†æœ€ç»ˆä»å»ºè®®äººå·¥æ ‡æ³¨è‹¥å¹²ä¾‹å­è¿›è¡Œè´¨é‡è¯„ä¼°ã€‚
- Self-consistency å¢ç›Šæµ‹è¯•ï¼šæ¯”è¾ƒå¤šæ¬¡é‡‡æ ·åå¤šæ•°æŠ•ç¥¨çš„å‡†ç¡®ç‡æå‡ã€‚

ç¤ºä¾‹è¯„ä¼°è„šæœ¬ï¼ˆä¼ªå‘½ä»¤ï¼‰ï¼š
```bash
python eval.py --pred predictions.jsonl --gold data/test.jsonl --metrics accuracy,bleu,rouge
```

äººå·¥è¯„ä¼°å»ºè®®ï¼š
- éšæœºæŠ½æ · 200 ä¸ªæ ·æœ¬ï¼Œè®©äººå·¥è¯„ä¼° COT çš„æ­£ç¡®æ€§ï¼ˆæ¯æ¡æ ‡æ³¨ï¼šæ­£ç¡®/éƒ¨åˆ†æ­£ç¡®/é”™è¯¯ï¼‰ï¼Œå¹¶æŠ¥å‘Šæ¯”ä¾‹ã€‚

---

## 6. æ¨¡å‹å¡ä¸ä½¿ç”¨å£°æ˜ / Model Card & Usage
**ä¸»è¦ä¿¡æ¯**ï¼š
- æ¨¡å‹ï¼šåŸºäº Qwen3-ommi-thinking-30B å¾®è°ƒå¾—åˆ°çš„ COT å¼ºåŒ–æ¨¡å‹ã€‚
- è®¸å¯ï¼šè¯·åœ¨æ­¤å¤„è¡¥å……åŸºæ¨¡å‹ä¸è®­ç»ƒæ•°æ®è®¸å¯ä¿¡æ¯ï¼Œç¡®ä¿éµå®ˆæ•°æ®å’Œæ¨¡å‹è®¸å¯ã€‚

**é™åˆ¶ä¸é£é™©**ï¼š
- å¯¹éŸ³é¢‘è½¬å½•å™ªå£°æ•æ„Ÿï¼Œé”™è¯¯çš„éŸ³é¢‘ç‰¹å¾æˆ–è½¬å½•ä¼šå¼•èµ·é”™è¯¯æ¨ç†ã€‚
- Chain-of-Thought ç”Ÿæˆå¯èƒ½åŒ…å«ä¸å¯é æˆ–è™šæ„çš„ä¸­é—´æ­¥éª¤ï¼Œè¯·åœ¨å…³é”®æˆ–é«˜é£é™©åœºæ™¯ä¸­é‡‡ç”¨äººå·¥æ ¸æŸ¥ã€‚

**å…è´£å£°æ˜**ï¼š
- è¯·å‹¿å°†æœ¬æ¨¡å‹ç”¨äºä¸´åºŠã€æ³•å¾‹æˆ–å…¶ä»–é«˜é£é™©å†³ç­–åœºæ™¯ï¼Œé™¤éç»è¿‡ä¸¥æ ¼çš„éªŒè¯å’Œç›‘ç®¡åˆè§„æ€§å®¡æŸ¥ã€‚

---

## 7. å¤ç°è¯´æ˜ / Reproducibility ğŸ”
å¤ç°è¦ç‚¹ï¼š
1. å›ºå®šéšæœºç§å­ï¼ˆseedï¼‰å¹¶è®°å½•æ¨¡å‹/ä»£ç  commit hashã€‚
2. åˆ—å‡ºç¯å¢ƒä¾èµ–ï¼ˆå»ºè®®æä¾› `environment.yml` æˆ– `requirements.txt`ï¼‰ã€‚
3. æä¾›è®­ç»ƒæ—¥å¿—ä¸ checkpointã€é…ç½® YAML å’Œ tokenizer ä¿¡æ¯ã€‚

ç¤ºä¾‹ç¯å¢ƒä¾èµ–ï¼š
```
python==3.10
torch>=2.1
transformers
accelerate
bitsandbytes
numpy
scipy
librosa
llamaractory==<your_version>
```

---

## 8. å¸¸è§é—®é¢˜ / FAQ â“
Q: å¦‚ä½•åœ¨å†…å­˜/æ˜¾å­˜å—é™æƒ…å†µä¸‹è®­ç»ƒ 30B æ¨¡å‹ï¼Ÿ
A: ä½¿ç”¨ LoRA/PEFTã€8-bit ä¼˜åŒ–ï¼ˆbitsandbytesï¼‰ã€Deepspeed ZeROã€æˆ–åˆ†å¸ƒå¼å¤šå¡è®­ç»ƒæ¥é™ä½æ˜¾å­˜å ç”¨ã€‚

Q: å¦‚ä½•å¯¹ COT è¿›è¡Œè‡ªåŠ¨åŒ–è¯„åˆ†ï¼Ÿ
A: å¯ç»“åˆ BLEU/ROUGE/BERTScore åšè¿‘ä¼¼è¯„ä¼°ï¼Œä½† COT çš„æ­£ç¡®æ€§é€šå¸¸éœ€è¦äººå·¥æ ‡æ³¨æˆ–ä»»åŠ¡ç‰¹å®šè§„åˆ™æ¥åˆ¤å®šã€‚

---

## 9. å¼•ç”¨ / Citations ğŸ“š
- Audio-Reasoner æ•°æ®é›†ï¼ˆè¯·åˆ—å‡ºæ•°æ®é›†è®ºæ–‡/ä»“åº“å¼•ç”¨ï¼‰
- Qwen3 æ¨¡å‹è¯´æ˜ï¼ˆè¯·åˆ—å‡º Qwen å®˜æ–¹å¼•ç”¨ï¼‰
- Llamaractoryï¼ˆè¯·åˆ—å‡ºå¯¹åº”çš„é¡¹ç›®å¼•ç”¨ï¼‰

---

## è”ç³»ä¸åç»­å·¥ä½œ / Contact & Next steps
å¦‚æœä½ å¸Œæœ›æˆ‘ï¼š
- å°†è®­ç»ƒ/è¯„ä¼°è„šæœ¬æ”¾è¿› `scripts/` ä¸‹å¹¶æ·»åŠ  CI æµç¨‹ï¼Œæˆ–
- å°†ç¤ºä¾‹æ¨ç† notebook (`demo.ipynb`) æ·»åŠ åˆ°ä»“åº“ï¼Œ
è¯·å‘Šè¯‰æˆ‘ï¼Œæˆ‘å¯ä»¥ç»§ç»­ä¸ºä½ å®ç°è¿™äº›æ–‡ä»¶å¹¶æäº¤åˆ°ä¸»åˆ†æ”¯ã€‚ğŸ”§

---

**License / è®¸å¯**ï¼šåœ¨æœ¬ä»“åº“ä¸­è¯·è¡¥å……åˆé€‚çš„å¼€æºè®¸å¯ï¼ˆå¦‚ MIT/Apache-2.0ï¼‰å¹¶æ³¨æ˜ä¾èµ–çš„æ¨¡å‹ä¸æ•°æ®é›†è®¸å¯ã€‚

---

è°¢è°¢ï¼å¦‚æœä½ åŒæ„ï¼Œæˆ‘ç°åœ¨å¯ä»¥æŠŠä¸€ä»½ `scripts/` ç¤ºä¾‹è®­ç»ƒè„šæœ¬ã€ç¤ºä¾‹ `configs/finetune_cot.yaml`ã€ä»¥åŠ `examples/` çš„æ¨ç†/è¯„ä¼°è„šæœ¬ä¸€å¹¶æ·»åŠ åˆ°ä»“åº“ã€‚ğŸ¯
